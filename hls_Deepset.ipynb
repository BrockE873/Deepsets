{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# sys.path.append('/eos/home-i03/b/bewing/.local/lib/python3.9/site-packages')\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import uuid\n",
    "import hls4ml\n",
    "from hls4ml.model.graph import ModelGraph\n",
    "from hls4ml.model.layers import GRU, LSTM, SeparableConv1D, SeparableConv2D\n",
    "import profiling\n",
    "from profiling import *\n",
    "__tf_profiling_enabled__ = True\n",
    "__torch_profiling_enabled__ = True\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import mplhep as hep\n",
    "mpl.rcParams.update({'font.size': 20})\n",
    "\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "# # print(tf.__file__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Nadam\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Activation, Dense, Conv1D, Add, RepeatVector\n",
    "from tensorflow.keras.layers import Flatten, Reshape, GlobalAveragePooling1D, Concatenate, UpSampling1D, AveragePooling1D, MaxPooling1D  \n",
    "from tensorflow.keras import utils, regularizers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from qkeras import *\n",
    "import tensorflow.keras.layers as KL\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32\n",
    "from tensorflow.keras.layers import Dense, Layer\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_schedule, pruning_callbacks\n",
    "from tensorflow_model_optimization.sparsity.keras import UpdatePruningStep\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/eos/user/b/bewing/SWAN_projects/Research/Neural Network/data_split.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test, X_train2d, X_test2d, y_train2d, y_test2d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AAtt(keras.layers.Layer):\n",
    "    def __init__(self, d_model = 16, nhead = 1, nbits = 8, **kwargs):\n",
    "        super(AAtt, self).__init__(**kwargs)\n",
    "        \n",
    "        self.nbits = nbits\n",
    "        if self.nbits == 1:\n",
    "            qbits = 'binary(alpha=1)'\n",
    "        elif self.nbits == 2:\n",
    "            qbits = 'ternary(alpha=1)'\n",
    "        else:\n",
    "            qbits = 'quantized_bits({},0,alpha=1)'.format(nbits)\n",
    "\n",
    "        # qact = 'quantized_relu({},0)'.format(nbits)\n",
    "\n",
    "        dense_kwargs = dict(\n",
    "            # kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "            # kernel_regularizer = regularizers.l2(0.0001),\n",
    "            # bias_regularizer = regularizers.l2(0.0001),\n",
    "            # kernel_constraint = tf.keras.constraints.max_norm(5),\n",
    "            kernel_quantizer = qbits,\n",
    "            bias_quantizer = qbits,\n",
    "        )\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_head = nhead\n",
    "\n",
    "        self.qD = QDense(self.d_model, **dense_kwargs)\n",
    "        self.kD = QDense(self.d_model, **dense_kwargs)\n",
    "        self.vD = QDense(self.d_model, **dense_kwargs)\n",
    "        self.outD = QDense(self.d_model, **dense_kwargs)\n",
    "\n",
    "def plotTrainingHistory(history, metrics = [\"loss\", \"accuracy\"], f = None, axs = None):\n",
    "    \n",
    "    # creating the plot\n",
    "    if not f and not axs:\n",
    "        f, axs = plt.subplots(len(metrics), 1, figsize = (12, 4*len(metrics)), sharex = True)\n",
    "    if len(metrics) == 1:\n",
    "        axs = [axs]\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    for i in range(len(metrics)):\n",
    "        \n",
    "        metric = metrics[i]\n",
    "        ax = axs[i]\n",
    "        ax.set_ylabel(metric)\n",
    "        \n",
    "        if isinstance(history, list): # handle kfold\n",
    "            for foldi in range(len(history)):\n",
    "                ax.plot(history[foldi].history[metric], color = \"C{}\".format(foldi))\n",
    "                ax.plot(history[foldi].history['val_' + metric], color = \"C{}\".format(foldi), linestyle = \"--\")\n",
    "                \n",
    "            la2, = ax.plot([0,0], [0,0], color=\"Grey\")\n",
    "            lb2, = ax.plot([0,0], [0,0], color=\"Grey\", linestyle = \"--\")\n",
    "            ax.legend([la2, lb2], [\"training\", \"validation\"])\n",
    "        else: \n",
    "            xs = np.arange(len(history.history['val_' + metric]))\n",
    "            ax.plot(xs,history.history[metric], label = 'training')\n",
    "            ax.plot(xs+.5, history.history['val_' + metric], label= 'validation')\n",
    "            ax.legend()\n",
    "\n",
    "    axs[-1].set_xlabel(\"Epoch\")\n",
    "    \n",
    "    return f, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDeepSet(nclasses, input_shape, nnodes_phi = 16, nnodes_rho = 16, addRegression = False, nLayers = 3):\n",
    "    act = \"relu\"\n",
    "    inp = Input(shape = input_shape, name = \"inputs\")\n",
    "    h = BatchNormalization(name='batchnorm')(inp)\n",
    "    for iLayer in range(1, nLayers):\n",
    "        h = Dense(nnodes_phi, name='Dense_phi'+str(iLayer))(h)\n",
    "        h = Activation(act,name='Activation_phi'+str(iLayer))(h)\n",
    "    h = Dense(nnodes_phi, name='Dense_phi'+str(nLayers))(h)\n",
    "    phi_out = Activation(act,name='Activation_phi'+str(nLayers))(h)\n",
    "    mean = GlobalAveragePooling1D(name='avgpool')(phi_out)\n",
    "    h = Dense(nnodes_rho, name='Dense_rho1')(mean)\n",
    "    h = Activation(act,name='Activation_rho1')(h)\n",
    "    for iLayer in range(2,nLayers):\n",
    "        h = Dense(nnodes_rho*2, name='Dense_rho'+str(iLayer))(h)\n",
    "        h = Activation(act,name='Activation_rho'+str(iLayer))(h)\n",
    "    h_out = Dense(nnodes_rho, name='qDense_rho'+str(nLayers)+'_class')(h)\n",
    "    h_out = Activation(act,name='qActivation_rho'+str(nLayers)+'_class')(h_out)\n",
    "    h_out = Dense(nclasses, name='qDense_rho'+str(nLayers+1)+'_class')(h_out)\n",
    "    out = Activation('sigmoid', name='output_class')(h_out)\n",
    "\n",
    "    if addRegression:\n",
    "        h_reg = Dense(nnodes_rho, name='qDense_rho'+str(nLayers)+'_reg')(h)\n",
    "        h_reg = Activation(qact,name='qActivation_rho'+str(nLayers)+'_reg')(h_reg)\n",
    "        h_reg = Dense(1, name='qDense_rho4_reg')(h_reg)\n",
    "        out_reg = Activation('linear', name='output_reg')(h_reg)\n",
    "\n",
    "    # Build the model\n",
    "    if addRegression:\n",
    "        model = Model(inputs=inp, outputs=[out, out_reg])\n",
    "    else:\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    # Set NN and output name\n",
    "    arch = 'DeepSets_PermutationInv'\n",
    "    fname = arch+'_nconst_'+str(input_shape[0])+\"_nfeatures_\"+str(input_shape[1])\n",
    "\n",
    "    custom_objects = {\n",
    "        }\n",
    "\n",
    "\n",
    "    return model, fname, custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQDeepSet(nclasses, input_shape, nnodes_phi = 16, nnodes_rho = 16, nbits = 8, integ = 0, nLayers=3, addRegression = False):\n",
    "\n",
    "    # Define DeepSet Permutation Invariant Model\n",
    "\n",
    "    # baseline keras model\n",
    "\n",
    "    #########################################################################################################\n",
    "    '''\n",
    "    # Silence the info from tensorflow in which it brags that it can run on cpu nicely.\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "    keras.utils.set_random_seed(123)\n",
    "    import absl.logging\n",
    "    absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "    from util.terminal_colors import tcols\n",
    "    from . import util as dsutil\n",
    "\n",
    "    tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "    util.util.device_info()\n",
    "    outdir = util.util.make_output_directory(\"trained_deepsets\", args[\"outdir\"])\n",
    "    util.util.save_hyperparameters_file(args, outdir)\n",
    "\n",
    "    data = Data.shuffled(**args[\"data_hyperparams\"])\n",
    "    '''\n",
    "    #########################################################################################################\n",
    "\n",
    "    # Quantized bits\n",
    "    qbits = quantized_bits(nbits,integ,alpha=1.0)\n",
    "    qact = 'quantized_relu('+str(nbits)+',0)'\n",
    "\n",
    "    # Set QKeras quantizer and activation \n",
    "    if nbits == 1:\n",
    "        qbits = 'binary(alpha=1)'\n",
    "    elif nbits == 2:\n",
    "        qbits = 'ternary(alpha=1)'\n",
    "    else:\n",
    "        qbits = 'quantized_bits({},0,alpha=1)'.format(nbits)\n",
    "\n",
    "    qact = 'quantized_relu({},0)'.format(nbits)\n",
    "\n",
    "    # Print\n",
    "    # print(\"Training with max # of contituents = \", nconstit)\n",
    "    # print(\"Number of node features = \", nfeat)\n",
    "    print(\"Quantization with nbits =\",nbits)\n",
    "    print(\"Quantization of integer part =\",integ)\n",
    "\n",
    "    #############################################################################\n",
    "    # nnodes_phi = 32\n",
    "    # nnodes_rho = 32\n",
    "    # nnodes_phi = 16\n",
    "    # nnodes_rho = 16\n",
    "    # nnodes_phi = 24\n",
    "    # nnodes_rho = 24\n",
    "    # activ      = \"relu\"\n",
    "    # activ      = \"selu\"\n",
    "    #activ      = \"elu\"\n",
    "    # REGL = regularizers.L1(0.0001) \n",
    "    REGL = regularizers.l2(0.0001)\n",
    "    kernel_initializer_=tf.keras.initializers.glorot_normal()\n",
    "    kernel_constraint = tf.keras.constraints.max_norm(5)\n",
    "\n",
    "    dense_kwargs = dict(\n",
    "        # kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "        # kernel_regularizer = REGL,\n",
    "        # bias_regularizer = REGL,\n",
    "        # kernel_constraint = tf.keras.constraints.max_norm(5),\n",
    "        kernel_quantizer = qbits,\n",
    "        bias_quantizer = qbits,\n",
    "        # dropout=0.1,\n",
    "    )\n",
    "\n",
    "    # Instantiate Tensorflow input tensors in Batch mode \n",
    "    inp = Input(shape = input_shape, name = \"inputs\")\n",
    "\n",
    "    # Input point features BatchNormalization \n",
    "    # h = QBatchNormalization(name='qBatchnorm', beta_quantizer=qbits, gamma_quantizer=qbits)(inp)\n",
    "    # h = QBatchNormalization(name='qBatchnorm', beta_quantizer=qbits, gamma_quantizer=qbits, mean_quantizer=qbits, variance_quantizer=qbits)(inp)\n",
    "    h = BatchNormalization(name='batchnorm')(inp)\n",
    "    # Phi MLP ( permutation equivariant layers )\n",
    "    for iLayer in range(1, nLayers):\n",
    "        h = QDense(nnodes_phi, name='Dense_phi'+str(iLayer),**dense_kwargs)(h)\n",
    "        h = QActivation(qact,name='Activation_phi'+str(iLayer))(h)\n",
    "    h = QDense(nnodes_phi, name='Dense_phi'+str(nLayers),**dense_kwargs)(h)\n",
    "    phi_out = QActivation(qact,name='Activation_phi'+str(nLayers))(h)\n",
    "    \n",
    "    \n",
    "    # Linear activation to change HLS bitwidth to fix overflow in AveragePooling\n",
    "    #h = QActivation(activation='quantized_bits(14,5)', name = 'linear_activation')(h)\n",
    "    \n",
    "    phi_out = QActivation(activation='quantized_bits(18,8)', name = 'qActivationForPool')(phi_out)\n",
    "\n",
    "    \n",
    "    # Aggregate features (taking mean) over set elements  \n",
    "    mean = GlobalAveragePooling1D(name='avgpool')(phi_out)      # return mean of features over elements\n",
    "    # mean = GlobalAveragePooling1D(name='avgpool', keepdims=False)(phi_out)      # return mean of features over elements\n",
    "\n",
    "    # Rho MLP\n",
    "    h = QDense(nnodes_rho, name='qDense_rho1', **dense_kwargs)(mean)\n",
    "    h = QActivation(qact,name='qActivation_rho1')(h)\n",
    "    for iLayer in range(2,nLayers):\n",
    "        h = QDense(nnodes_rho*2, name='Dense_rho'+str(iLayer),**dense_kwargs)(h)\n",
    "        h = QActivation(qact,name='Activation_rho'+str(iLayer))(h)\n",
    "    h_out = QDense(nnodes_rho, name='qDense_rho3', **dense_kwargs)(h)\n",
    "    h_out = QActivation(qact,name='qActivation_rho3')(h_out)\n",
    "    h_out = QDense(nclasses, name='qDense_rho4', **dense_kwargs)(h_out)\n",
    "    out = Activation('sigmoid', name='output_class')(h_out)\n",
    "\n",
    "    if addRegression:\n",
    "        h_reg = QDense(nnodes_rho, name='qDense_rho3_reg', **dense_kwargs)(h)\n",
    "        h_reg = QActivation(qact,name='qActivation_rho3_reg')(h_reg)\n",
    "        h_reg = QDense(1, name='qDense_rho4_reg', **dense_kwargs)(h_reg)\n",
    "        out_reg = Activation('linear', name='output_reg')(h_reg)\n",
    "\n",
    "    # Build the model\n",
    "    \n",
    "    if addRegression:\n",
    "        model = Model(inputs=inp, outputs=[out, out_reg])\n",
    "    else:\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    # Set NN and output name\n",
    "    arch = 'QDeepSets_PermutationInv'\n",
    "    fname = arch+'_nconst_'+str(input_shape[0])+\"_nfeatures_\"+str(input_shape[1])+'_nbits_'+str(nbits)\n",
    "\n",
    "    custom_objects = {\n",
    "        \"AAtt\": AAtt,\n",
    "        \"QDense\": QDense,\n",
    "        \"QActivation\": QActivation,\n",
    "        \"quantized_bits\": quantized_bits,\n",
    "        \"ternary\": ternary,\n",
    "        \"binary\": binary,\n",
    "        \"QBatchNormalization\": QBatchNormalization\n",
    "        }\n",
    "\n",
    "\n",
    "    return model, fname, custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalMinBiasRate():\n",
    "\n",
    "    LHCfreq = 11245.6\n",
    "    nCollBunch = 2544\n",
    "\n",
    "    return LHCfreq * nCollBunch / 1e3 # in kHz\n",
    "# fpr *= totalMinBiasRate()\n",
    "# qfpr *= totalMinBiasRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruneFunction(layer):\n",
    "    pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.5, begin_step=6000, frequency=10)}\n",
    "                \n",
    "            # Apply prunning to Dense layers type excluding the output layer\n",
    "    if isinstance(layer, tf.keras.layers.Dense) and layer.name != 'dense_out': # exclude output_dense\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deepset, fname, objects = getDeepSet(1, X_train2d.shape[1:])\n",
    "adamDS = Adam(learning_rate = .0001)\n",
    "Deepset.compile(optimizer=adamDS, loss=['binary_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDeepset, fname, objects = getQDeepSet(1, X_train2d.shape[1:])\n",
    "QDeepset = tf.keras.models.clone_model(QDeepset, clone_function=pruneFunction)\n",
    "adamQDS = Adam(learning_rate = .0001)\n",
    "QDeepset.compile(optimizer=adamQDS, loss=['binary_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "pr = pruning_callbacks.UpdatePruningStep()\n",
    "history = Deepset.fit(X_train2d, y_train2d, batch_size=1024, epochs=100, validation_split=0.25, shuffle=True)# callbacks=[earlystop_callback])\n",
    "fig0, _ = plotTrainingHistory(history)\n",
    "history = QDeepset.fit(X_train2d, y_train2d, batch_size=1024, epochs=100, validation_split=0.25, shuffle=True, callbacks=[earlystop_callback,pr])\n",
    "fig1, _ = plotTrainingHistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDeepset = strip_pruning(QDeepset)\n",
    "QDeepset.compile(optimizer=adamQDS, loss=['binary_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = True\n",
    "hls4ml.model.optimizer.get_optimizer(\"output_rounding_saturation_mode\").configure(\n",
    "        layers=[\n",
    "#            \"qrelu_n1\",\n",
    "#            \"qrelu_g1\",\n",
    "#            \"softmax_g2\",\n",
    "        ],\n",
    "        rounding_mode=\"AP_RND\",\n",
    "        saturation_mode=\"AP_SAT\",\n",
    "    )\n",
    "config = hls4ml.utils.config_from_keras_model(\n",
    "        QDeepset, granularity=\"name\",\n",
    "        # default_precision=\"ap_fixed<16,6>\"\n",
    "        default_precision=\"ap_fixed<20,9>\"\n",
    "    )\n",
    "config[\"Model\"][\"Strategy\"] = \"Latency\"\n",
    "\n",
    "    # Handle large span of numerical values in input\n",
    "    # inputPrecision = \"ap_fixed<12,4,AP_RND,AP_SAT>\"\n",
    "    # inputPrecision = \"ap_fixed<16,7,AP_RND,AP_SAT>\"\n",
    "    # inputPrecision = \"ap_fixed<18,8,AP_RND,AP_SAT>\"\n",
    "inputPrecision = \"ap_fixed<20,9,AP_RND,AP_SAT>\"\n",
    "\n",
    "print (\"Default generated config\")\n",
    "print (config)\n",
    "\n",
    "for layer in QDeepset.layers:\n",
    "        if layer.__class__.__name__ in [\"BatchNormalization\", \"InputLayer\"]:\n",
    "            config[\"LayerName\"][layer.name][\"Precision\"] = inputPrecision\n",
    "            config[\"LayerName\"][layer.name][\"result\"] = inputPrecision\n",
    "            config[\"LayerName\"][layer.name][\"Trace\"] = trace\n",
    "        elif layer.__class__.__name__ in [\n",
    "            \"Permute\",\n",
    "            \"Concatenate\",\n",
    "            \"Flatten\",\n",
    "            \"Reshape\",\n",
    "            # \"GlobalAveragePooling1D\",\n",
    "            # \"AveragePooling1D\",\n",
    "            \"UpSampling1D\",\n",
    "            \"Add\",\n",
    "        ]:\n",
    "            print(\"Skipping trace for:\", layer.name)\n",
    "        else:\n",
    "            config[\"LayerName\"][layer.name][\"Trace\"] = trace\n",
    "\n",
    "        for layerName in config[\"LayerName\"]:\n",
    "            config[\"LayerName\"][layerName][\"Trace\"] = True\n",
    "\n",
    "\n",
    "config[\"LayerName\"][\"output_class\"][\"Precision\"][\"result\"] = inputPrecision\n",
    "    \n",
    "config[\"LayerName\"][\"avgpool\"][\"Precision\"][\"result\"] = inputPrecision\n",
    "config[\"LayerName\"][\"avgpool\"][\"Precision\"] = inputPrecision\n",
    "\n",
    "config[\"LayerName\"][\"qActivationForPool\"][\"Precision\"][\"result\"] = inputPrecision\n",
    "config[\"LayerName\"][\"qActivationForPool\"][\"Precision\"] = inputPrecision\n",
    "\n",
    "config[\"LayerName\"][\"output_class\"][\"Implementation\"] = \"latency\"\n",
    "\n",
    "print (\"Changed  config\")\n",
    "print (config)\n",
    "\n",
    "for layer in QDeepset.layers:\n",
    "        if \"qDense_phi\" in layer.name:\n",
    "            print (\"Add custom pointwise implementation for layer\", layer.name)\n",
    "            config[\"LayerName\"][layer.name][\"ConvImplementation\"] = \"Pointwise\"\n",
    "\n",
    "\n",
    "layerNames = [layer.name for layer in QDeepset.layers]\n",
    "\n",
    "for layer in QDeepset.layers:\n",
    "        config[\"LayerName\"][layer.name][\"Strategy\"] = \"latency\"\n",
    "\n",
    "print(\"Converting the Keras Model !\")\n",
    "\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "        QDeepset,\n",
    "        hls_config=config,\n",
    "        # output_dir=output_dir,\n",
    "        output_dir='Models',\n",
    "        io_type=\"io_parallel\",\n",
    "#        part=\"xcvu9p-flgb2104-2l-e\",\n",
    "        # part=\"xcvu13p-flga2577-2-e\", #real one\n",
    "        part=\"xcu250-figd2104-2L-e\",\n",
    "        clock_period=2.5,\n",
    "        # part=\"xcvu13p-flga2577-2-e\",\n",
    "        # clock_period=2.777777778,\n",
    ")\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_ds = Deepset.predict(X_test2d)\n",
    "y_test_pred_qds = QDeepset.predict(X_test2d)\n",
    "y_hls = hls_model.predict(X_test2d)\n",
    "fpr, tpr, thr = roc_curve(y_test2d, y_test_pred_ds, drop_intermediate =False)\n",
    "qfpr, qtpr, qthr = roc_curve(y_test2d, y_test_pred_qds, drop_intermediate =False)\n",
    "hlsfpr, hlstpr, hlsthr = roc_curve(y_test2d, y_hls, pos_label=1, sample_weight=None, drop_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test2d, y_test_pred_ds)\n",
    "qroc_auc = roc_auc_score(y_test2d, y_test_pred_qds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlsfpr *= totalMinBiasRate()\n",
    "hlsroc_auc = roc_auc_score(y_test2d, y_hls)\n",
    "\n",
    "f, ax  = plt.subplots(figsize=(8,6))\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14) \n",
    "ax.set_xlim(0,100)\n",
    "\n",
    "ax.plot(fpr, tpr, color='green', lw=2, ls='dashed', label=f'Baseline (AUC = {roc_auc:.5f})')\n",
    "ax.plot(qfpr, qtpr, color='red', lw=2, label=f'Quantized+Pruned (AUC = {qroc_auc:.5f})')\n",
    "ax.plot(hlsfpr, hlstpr, color='purple', lw=3, ls='dotted', label=f'HLS Quantized+Pruned (AUC = {hlsroc_auc:.5f})')\n",
    "ax.set_xlabel('L1 Rate (kHz)')\n",
    "ax.set_ylabel('Signal efficiency')\n",
    "ax.legend(prop={'size': 10},loc=\"lower right\")\n",
    "ax.grid(True)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,1)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_small = X_test2d[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_model(model, hls_model, X_test_small):\n",
    "    print(\"Running tracing!\")\n",
    "\n",
    "    # Function to get Keras model outputs excluding the input layer\n",
    "    def get_keras_outputs(model, X):\n",
    "        # Get all layers except the InputLayer\n",
    "        layers_to_trace = [layer for layer in model.layers if not isinstance(layer, tf.keras.layers.InputLayer)]\n",
    "        # Create a partial model to trace only these layers\n",
    "        partial_model = tf.keras.models.Model(inputs=model.inputs, outputs=[layer.output for layer in layers_to_trace])\n",
    "        # Predict outputs\n",
    "        y = partial_model.predict(X)\n",
    "        # Return list of outputs corresponding to each layer\n",
    "        return {layer.name: y[i] for i, layer in enumerate(layers_to_trace)}\n",
    "\n",
    "    # Generate Keras model outputs excluding input layer\n",
    "    keras_outputs = get_keras_outputs(model, X_test_small)\n",
    "\n",
    "    # Perform trace for HLS model\n",
    "    y_hls, hls4ml_trace = hls_model.trace(X_test_small)\n",
    "\n",
    "    # Get QKeras model outputs for comparison\n",
    "    keras_trace = get_keras_outputs(model, X_test_small)\n",
    "\n",
    "    for layer in hls4ml_trace.keys():\n",
    "        print(\"Doing profiling 2d for layer\", layer)\n",
    "        plt.figure()\n",
    "        plt.scatter(hls4ml_trace[layer].flatten(), keras_trace[layer].flatten(), s=0.2)\n",
    "        min_x = min(np.amin(hls4ml_trace[layer]), np.amin(keras_trace[layer]))\n",
    "        max_x = max(np.amax(hls4ml_trace[layer]), np.amax(keras_trace[layer]))\n",
    "        plt.plot([min_x, max_x], [min_x, max_x], c=\"gray\")\n",
    "        plt.xlabel(\"hls4ml {}\".format(layer))\n",
    "        plt.ylabel(\"QKeras {}\".format(layer))\n",
    "        plt.savefig(f\"profile_2d_{layer}.png\")\n",
    "        plt.savefig(f\"profile_2d_{layer}.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    return y_hls, hls4ml_trace, keras_trace\n",
    "\n",
    "# Example usage:\n",
    "# Replace QDeepset with your model and hls_model with your HLS model\n",
    "# Replace X_test_small with your test data\n",
    "# y_hls, hls4ml_trace, keras_trace = trace_model(QDeepset, hls_model, X_test_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_model(QDeepset,hls_model,X_test_small)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
